const essayArray = [
    {
        "Title": "<h2>Case Study: Takealot – Ethics, UI, UX and Interaction</h2>",
        "Topic": "<h3>Ethics, UI, UX, and Interaction</h3>",
        "num": "<p>Essay 1</p>",
        "par1": "<p>The website that offers services in South Africa that I’ve chosen to discuss is: Takealot, an online marketplace. I chose this website, since my family and I have been using it for years and we have noticed things that work well… and things that don’t.  It is a commonly used website in South Africa (SimilarWeb [1] places it at no. 20  of the most used sites, while SemRush [2] places it at no. 19 in March 2023 – both place Takealot at no. 1 for most used eCommerce & Shopping sites*) and due to this site’s ubiquity in South Africa, I felt it to be a good case study to look at in terms of ethics, UI, UX, and Interaction (it affects many South African lives).</p>",
        "par2": "<p>*Note: SimilarWeb and SemRush, when visited will show the previous month’s statistics, and at the time of writing this essay the previous month is March 2023, however this placing in the ranks is most likely to stay relatively consistent when checking these tracker sites in later months of this year unless another site becomes wildly popular and overtakes Takealot in the near future.</p>",
        "par3": "<p>Firstly, I’ll discuss the ethics surrounding the Takealot website, as well as the ethics of the site’s interaction design and UI.</p>",
        "par4": "<p>To start off, when you simply Google search “online shop” in South Africa one of the first results are sponsored links for Takealot and other big eCommerce sites. While this is more of an ethical issue on Google’s side (changing search engine results for profit), Takealot is still involved, since they pay for the sponsored link. This is likely one of the reasons Takealot is currently (at time of writing this essay) ranked no. 1 among eCommerce & Shopping sites, since most people click on one of the first links given to them by Google’s search engine. In fact, as reported by Search Engine Journal [3], the first link gets over a quarter of search engine users to click it. Sponsored links have become more ubiquitously used by big sites to stay on top of the search engine result list.</p>",
        "par5": "<p>Now, going into Takealot [4] itself, the first thing you see (which is emphasized by it’s dominating size in the centre of the screen) is sponsored adverts and a list of featured brands. These advertisement’s placement and over prominence on screen draw the user’s attention away from the simple and bland search bar (which is most likely the first thing a user would like to interact with in any site with a huge catalogue of items). While the search bar is not “hidden” it is placed in proximity to other rectangles (that leads to other sections such as “Loadshedding” or “Deals & Promotions”) and all of the similar-looking elements are in bland whites and greys so that the colourful adverts draw the user’s attention easier. The UI is nudging against the user’s best interest and deliberately distracts the user from their original goals when entering the website. These are ethical issues touched upon in Week 7’s lecture slides [5].</p>",
        "par6": "<p>When searching for items on Takealot, the first items related to your search, like with the above-mentioned Google search results, are marked “Sponsored”. These sponsored items are put in front to catch the attention of the user but quite often might not be exactly what the user is looking for. For example, when I searched “ps5” (on 28 April 2023**) the first two items shown to me is an unofficial cooling stand (not made by Sony) and a Nintendo Switch dock set. These items are not something I would want to purchase when looking for Sony PlayStation products. Especially promoting unofficial third-party accessories before the actual product can nudge users to make a sub-optimal purchasing decision. When I searched “Sony ps5” (on 28 April 2023**), the first two (sponsored) items are headsets not made by Sony. In both searches, only the third item was official Sony PlayStation products.</p>",
        "par7": "<p>**Note: the sponsored items mentioned in my example change with every search and the sponsors will likely change with time. Recreating the test of searching “ps5” or “Sony ps5” might yield slightly different results.</p>",
        "par8": "<p>Other ethical issues with Takealot involve the use of dark patterns, specifically having ambiguous sales deadlines [6] (no deadlines obviously given to users) or making it look like an item is on sale, but in actuality: the crossed-out higher price actually being the recommended retailer “list price” and the lower price only being the usual Takealot pricing for the item.*** These practices put false urgency on the user or create the illusion of an opportunity to get an item for cheaper in order to trick the user into considering buying an item they wouldn’t otherwise in other circumstances. While these practices aren’t illegal, especially since they are disclosed in the terms and conditions of the website, it is still unethical. I myself have thought I’ve gotten a good deal on an item from Takealot, but upon investigating the site for this essay, I am now disillusioned with that notion. The main unethical factor of this, is that it took me investigating the site to realize this – I had to click on a small, greyed-out “i”-icon next to the greyed-out, crossed-out pricing to make a pop-up appear, then clicking on the terms and conditions link on the pop-up, then (in the terms of conditions page) using ctrl+F to find-in-page the clause mentioning the “list price” referred to in the pop-up message. That is way too much effort for the average user to go through and this tedious method of getting to the desired clause discourages users from investigating these elements of the site.</p>",
        "par9": "<p>***Note: The term “list price” is explained in the website’s terms and conditions [7]</p>",
        "par10": "<p>Now to move on to further discussions on the UI, UX, and Interaction of Takealot and how they can be helpful to the user.</p>",
        "par11": "<p>From an IxD Process perspective, the goal of the website is to give users (potential online shoppers) access to a shopfront where they can easily search for items (or categories of items) they wish to buy. c, the content mapping of the website is as follows. The homepage showcases featured brands, popular categories, sales, advertisements, and a list of categories. At the top of each page are the navigation (to log-in, register and order pop-up menus as well as the user’s account page) and the search bar. One problem with the search bar being at the top of the page, and not fixed to the user’s scrolling: in order to make a new search the user must scroll all the way back to the top of the current page. Once the user has made a search query, the resulting page shows filters and category refinements on the far left, and then the actual store items make up the majority of the rest of the page. Unlike the homepage, there are no advertisements on the right side of the search results page to allow more room for the store items and the filters. The “advertisements” take the form of sponsored items in between the other store items you’ve searched for.</p>",
        "par12": "<p>The user flow, at the time of writing this, is as follows: after entering the website the user will see advertisements, a list of categories to shop from, the search bar and simple navigation (to user’s account or shopping cart). The user can then either scroll down to see deals or previously searched (but not bought) items or the user can interact with the search bar or category list to start finding items they wish to buy. After they reach a page (category or specific search result) the player can scroll down to view the different products. Once the user selects a product, they go to that product’s page, where they find more detailed information and reviews on the product. From here the user can add the item to their cart, or investigate similar products that are recommended. Once the user has added all the items they wish to their cart they can navigate to their cart page and proceed to checkout in order to purchase these items (The user will decide payment methods and whether to pick up the item or have it delivered).</p>",
        "par13": "<p>Looking at some core UI principles and methodologies employed by Takealot. The website, like many online store-fronts, leverages the Zeigarnik effect [8] by making the user have a shopping cart before making a final purpose. The user adds an item to the cart and continues searching for other items, all the while the items in the cart is in the back of the user’s mind and reinforces by the non-zero number in the green cart icon at the top of each page you visit in the website. The user is less likely to forget to buy or to navigate away from the site before making a final purchasing decision. While this is not necessarily a dark UX pattern, since the main purpose of online shopping carts is user convenience when purchasing multiple items at once (or in this site’s case, ordering for one single bulk delivery), it still has a small effect on user’s decision making. Other than this, most core UI principles are upheld quite nicely. The website is consistent, has a simple and understandable UI structure, uses conventions of other online store-fronts, and gives the user the proper amount of control and information of their current situation (such as what’s in their cart, the total price, whether the purchase went through, how long until delivery, notifications of delivery status, etc.) as well as many others discussed during various lectures and readings during the first block.</p>",
        "par14": "<p></p>",
        "par15": "<p></p>",
        "par16": "<p></p>",
        "par17": "<p></p>",
        "par18": "<p></p>",
        "par19": "<p></p>",
        "par20": "<p></p>",
    },
    {
        "Title": "<h2>Algorithmic Culture and AI and their Impact on the Internet</h2>",
        "Topic": "<h3>AI Risk (Internet, Society and Design Justice)</h3>",
        "num": "<p>Essay 2</p>",
        "par1": "<p>The Statement on AI Risk [1], released by the Center for AI Safety, simply implies that AI is just as dangerous as any other apocalyptic scenario, such as nuclear war, and must be treated as such. This is a rare case of the “reference list” being longer than the content since this one sentence is corroborated by many AI experts and other notable people, such as CEOs, CTOs, COOs, academics, etc. The sheer amount of people who agree with this single statement should indicate that Algorithmic Culture and AI can have a negative impact, or even an apocalyptic impact, on the Internet and the world as a whole.</p>",
        "par2": "<p>Through the lens of the “Internet, Society and Design Justice”, there are many aspects, cases, and readings to consider when discussing the impact of AI, algorithms, and algorithmic culture on the Internet and its users.</p>",
        "par3": "<p>The internet has become one of the most widely used commodities in the world and one of the most important factors in the day-to-day life of many people. However, as stated by Claire Daniolou in “The Need for Global Internet Connectivity” [2], since internet connectivity is such a valuable resource, the groups of people who don’t have access to this resource are automatically marginalized and suffer from their severe lack of access to helpful information, means to contribute information to the greater whole and the means to simply communicate with others. This marginalization affects already marginalized groups, such as people from impoverished or rural areas, thus adding multipliers to their already existing inequalities and problems. And these are just the unintentional effects of the need for global internet connectivity – the internet can be used to intentionally mislead, misinform, and take advantage of non-internet-literate users, such as new users from areas only recently added to the “global web”.</p>",
        "par4": "<p>The users from these “lower access” areas are quite often low on many developers’ priority lists and thus are often excluded from consideration during the development of new algorithms and AIs, further increasing the marginalization of these communities. Current algorithmic culture quite often involves the “needs of the many outweigh the needs of the few” approach, i.e., norms, medians, means, and averages are almost always the focus of algorithms and AI, while excluding the outliers. In terms of those who have internet connectivity versus those who don’t: as of April of this year around 64% of the world’s population has internet access [3], which is a lot of people that benefit from this resource. However, that means 36%, i.e., around 2.8 billion people still don’t have access, which means not only are those 2.8 billion people marginalized in terms of internet access, internet-literacy, internet contribution, and internet communication, but they are also marginalized in terms of consideration within algorithms, AI and algorithmic culture. As the “outliers” in the data taken in by algorithms and AIs, those 2.8 billion people are excluded from many aspects of one of the most widely used commodities in the world and quite often this leads to many negative effects on those marginalized communities.</p>",
        "par5": "<p>For further examples and explanations on algorithmic culture and AI’s effect on the internet, look to “Algorithmic Injustices: Towards a Relational Ethics” written by Abeba Birhane and Fred Cummins [4]. In this paper, there is a focus put on how algorithms can disproportionally affect, i.e., marginalize, certain groups over others. Again, the focus on averages over outliers that are built into many algorithms and AIs leads to many problems, such as data biases within the algorithms, misrepresentation of groups or individuals and incorrectly flagging certain individuals due to their unimportant similarities to others (that are not connected to the problem that they are being flagged for). In fewer words: algorithmic stereotyping.</p>",
        "par6": "<p>Many data biases within algorithms and AIs are only seen after a disaster has occurred since many algorithms and AIs put focus on predictions over understanding. The crucial step of “understanding” is often skipped for the more immediate benefits of predictive algorithms and AIs. This leads to many ethical issues, such as the example discussed in the reading, [4], predicting future crimes - not only is it promoting a “guilty until proven innocent”, which is considered unethical by many law systems throughout the world,  it is going ahead without the crucial step of “understanding” and thus getting many predictions wrong. Mistakes in any justice system can ruin lives and must be avoided, but if a faulty AI or algorithm is trusted with such predictions – it could take a while to find out there are mistakes being made at all.</p>",
        "par7": "<p>A more well-known example of predictive AIs and algorithms lacking the understanding needed to accurately detect and predict outcomes is the famous “Google Guerrilla Scandal”. To summarize the blunder made by Google Photo’s AI software, the underlying algorithms took in data from photos of people with darker skin tones and tried to predict the content of the picture. Due to the data the AI was trained on, it lacked the base understanding of what constitutes a “human” and mislabelled these pictures under the category of “guerrillas” which understandably earned extreme backlash from users. Although Google has apologized and fixed the issue [5], similar hidden biases within the code and data sets of AIs and algorithms are still a massive problem today. They usually affect already marginalized groups and minorities simply due to the fact that those groups are underrepresented, not only in the user base of the internet, but also in terms of access to the internet, contributions to the internet, and the workforce of many technology companies. A more recent example of algorithms and AIs having data biases that negatively affect racial minorities is the government mobile app that immigrants use for asylum applications in the United States [6]. Many asylum seekers could not even use the app if they have a darker skin tone since the facial scanning algorithms simply did not recognize their faces. This was a huge mistake on the coding side since, while the users are from a racial minority, due to geographic location they formed the majority of the user base of the app, which should classify the algorithm as a total failure to its target audience. This mistake is most likely due to a lack of diversity in the development team or the other general problems with the algorithmic culture this essay has highlighted thus far. The lack of diversity in many software development teams often leads to unintentional biases within the code. As the article, [6], also highlights most facial recognition software is most accurate when dealing with middle-aged white men, which most likely is the main demographic of the developers.</p>",
        "par8": "<p>While there is no easy solution to these issues, one path to bettering algorithmic culture and AI is: Design Justice. The core principles, as laid out by Sasha Costanza-Chock in “Introduction: #TravelingWhileTrans, Design Justice, and Escape from the Matrix of Domination” [7], involve designing and developing with representation, inclusion, consideration, empathy, empowerment, and community in mind. Design Justice involves thinking of the process of ‘design’ differently than the usual algorithmic culture. Developers must focus on the impact of the product on users, rather than designed intentions. Designers must focus on the communities that are affected by their product, taking a user-centred approach, while on the developer side is always a good idea to promote diversity in the development team. Diversity in the workforce will bring more perspectives to the design and limit any potential biases that the algorithms or AIs might have. It is important to be inclusive, not only when designing, but also when sharing design knowledge with groups that are thus far underrepresented in the overall software workforce as well as the community of internet contributors. </p>",
        "par9": "<p>Design Justice as a concept can be summarized as user-centred and community-centred design with the explicit intent to promote and facilitate diversity, inclusion, and representation in every step of development. From the initial conception of an idea to the process of developing algorithms and generating data sets, all the way to the impact it will have on the end-users. While Design Justice as a concept certainly should be implemented in every design sector and not just in the software sector, the current algorithmic culture and the “needs of the many outweigh the needs of the few” design philosophy of many software designers requires us to put a focus on this sector. The problems that can be caused by AI and algorithmic culture will only become more extreme and grow more numerous, with the growing number of people connected to the internet and the growing demand for software that require AI and sophisticated predictive algorithms.</p>",
        "par10": "<p>The Statement on AI Risk [1], released by the Center for AI Safety, simply outlines that AI, algorithms, and algorithmic culture has and will continue to have problems for the foreseeable future. And if these issues are not taken seriously and serious change is not implemented in the design process, they will create pain, heartache, exploitation, discrimination, or even a disaster of an apocalyptic scale. One way to facilitate the mitigation of the risk of AI and algorithms, which the statement says should be a priority, is the Design Justice approach. If a diverse group of people, with different areas of expertise and backgrounds of knowledge, works together, and a special focus is put on the impact of technology on its users and communities, many of these risks will be avoided in the process.</p>",
        "par11": "<p></p>",
        "par12": "<p></p>",
        "par13": "<p></p>",
        "par14": "<p></p>",
        "par15": "<p></p>",
        "par16": "<p></p>",
        "par17": "<p></p>",
        "par18": "<p></p>",
        "par19": "<p></p>",
        "par20": "<p></p>",
    }
];

const referenceArray = [
    {
        "num": "<p>Essay 1</p>",
        "ref1": "<p>[1] 	SimilarWeb, 'Top Websites Ranking - Most Visited Websites in South Africa,' SimilarWeb, 1 April 2023. [Online]. Available: https://www.similarweb.com/top-websites/south-africa/. [Accessed 28 04 2023].</p>",
        "ref2": "<p>[2] 	SemRush, 'Top websites,' SemRush, 13 April 2023. [Online]. Available: https://www.semrush.com/website/top/south-africa/all/. [Accessed 28 04 2023].</p>",
        "ref3": "<p>[3] 	M. G. Southern, 'Over 25% of People Click the First Google Search Result,' Search Engine Journal, 14 July 2020. [Online]. Available: https://www.searchenginejournal.com/google-first-page-clicks/374516/#close. [Accessed 28 04 2023].</p>",
        "ref4": "<p>[4] 	Takealot, 'takealot.com,' Takealot, [Online]. Available: https://www.takealot.com/. [Accessed 28 04 2023].</p>",
        "ref5": "<p>[5] 	P. Goldberg, 'ETHICS OF UX PRACTICE - YOU, YOUR AUDIENCE AND THE WEIGHT OF EXPERIENCE', p. 12 & 13.</p>",
        "ref6": "<p>[6] 	R. Steiner, 'Dark Patterns: A New Scientific Look At UX Deception,' Fyresite, 14 Feb 2020. [Online]. Available: https://www.fyresite.com/dark-patterns-a-new-scientific-look-at-ux-deception/. [Accessed 29 04 2023].</p>",
        "ref7": "<p>[7] 	Takealot, 'T&CS,' Takealot, [Online]. Available: https://www.takealot.com/help/terms-and-conditions#list-price. [Accessed 29 04 2023].</p>",
        "ref8": "<p>[8] 	L. Dukes, 'Psychology in design: the Zeigarnik effect,' UX Collective, 8 Oct 2020. [Online]. Available: https://uxdesign.cc/psychology-in-design-the-zeigarnik-effect-a59317503f8f. [Accessed 29 04 2023].</p>",
        "ref9": "<p></p>",
        "ref10": "<p></p>",
    },
    {
        "num": "<p>Essay 2</p>",
        "ref1": "<p>[1] 	Center for AI Safety, 'Statement on AI Risk,' 30 May 2023. [Online]. Available: https://www.safe.ai/statement-on-ai-risk#open-letter. [Accessed 14 06 2023].</p>",
        "ref2": "<p>[2] 	C. Daniolou, 'The Need for Global Internet,' Institute for Internet & the Just Society, 30 Oct 2020. [Online]. Available: https://www.internetjustsociety.org/the-need-for-global-internet-connectivity. [Accessed 14 06 2023].</p>",
        "ref3": "<p>[3] 	Statista, 'Number of internet and social media users worldwide as of April 2023(in billions),' Apr 2023. [Online]. Available: https://www.statista.com/statistics/617136/digital-population-worldwide/. [Accessed 15 06 2023].</p>",
        "ref4": "<p>[4] 	A. Birhane and F. Cummins, 'Algorithmic Injustices: Towards a Relational Ethics,' 16 Dec 2019. [Online]. Available: https://arxiv.org/abs/1912.07376v1 [cs.CY]. [Accessed 14 06 2023].</p>",
        "ref5": "<p>[5] 	BBC News, 'Google apologises for Photos app's racist blunder,' 1 July 2015. [Online]. Available: https://www.bbc.com/news/technology-33347866. [Accessed 15 06 2023].</p>",
        "ref6": "<p>[6] 	B. Debusmann-Jr, 'At US border, tech issues plague new migrant applications,' BBC News, 8 March 2023. [Online]. Available: https://www.bbc.com/news/world-us-canada-64814095. [Accessed 15 06 2023].</p>",
        "ref7": "<p>[7] 	S. Costanza-Chock, 'Introduction: #TravelingWhileTrans, Design Justice, and Escape from the Matrix of Domination,' Design Justice, 27 Feb 2020. [Online]. Available: https://designjustice.mitpress.mit.edu/pub/ap8rgw5e/release/1t. [Accessed 16 06 2023].</p>",
        "ref8": "<p></p>",
        "ref9": "<p></p>",
        "ref10": "<p></p>",
    }
];

const essay1Button = document.querySelector('#Essay01Button');
essay1Button.addEventListener("click", () => DisplayEssay(0));
const essay2Button = document.querySelector('#Essay02Button');
essay2Button.addEventListener("click", () => DisplayEssay(1));


let displayedEssay = document.getElementById("EssayDisplay");


function DisplayEssay(i)
{
    displayedEssay.innerHTML =  essayArray[i].num + essayArray[i].Title + essayArray[i].Topic + essayArray[i].par1 + essayArray[i].par2 
        + essayArray[i].par3 + essayArray[i].par4 + essayArray[i].par5 + essayArray[i].par6 + essayArray[i].par7 + essayArray[i].par8 + essayArray[i].par9
        + essayArray[i].par10 + essayArray[i].par11 + essayArray[i].par12 + essayArray[i].par13 + essayArray[i].par14 + essayArray[i].par15 + essayArray[i].par16
        + essayArray[i].par17 + essayArray[i].par18 + essayArray[i].par19 + essayArray[i].par20 + "<p>References:</p>" +  referenceArray[i].ref1 + referenceArray[i].ref2
        + referenceArray[i].ref3 + referenceArray[i].ref4 + referenceArray[i].ref5 + referenceArray[i].ref6 + referenceArray[i].ref7 + referenceArray[i].ref8
        + referenceArray[i].ref9 + referenceArray[i].ref10;
}
